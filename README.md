# PrepPal : Interview Practice Partner

A conversational AI-powered web application that helps you practice job interviews with realistic, adaptive questioning and detailed feedback. Built with cutting-edge AI technology to simulate real human interviewer behavior.

---

## Table of Contents
1. [Features](#features)
2. [Architecture & Design Decisions](#architecture--design-decisions)
3. [Prerequisites](#prerequisites)
4. [Installation](#installation)
5. [Usage](#usage)
6. [Project Structure](#project-structure)
7. [How It Works](#how-it-works)
8. [Customization](#customization)
9. [Troubleshooting](#troubleshooting)
10. [Development Notes](#development-notes)

---

## Features

- üéØ **Role-Specific Interviews**: Software Engineer, Data Analyst, Sales, Customer Support
- üìä **Experience Levels**: Fresher, Junior, Mid, Senior
- üìÑ **Resume-Based Questions**: Upload your resume for personalized, experience-specific questions
- ü§ñ **Human-Like Conversation**: Natural, engaging dialogue that feels like a real interview
- üí¨ **Intelligent Follow-ups**: AI adapts questions based on your answers and resume
- üé§ **Voice Mode**: Speech-to-text input and text-to-speech output
- üìà **Detailed Feedback**: Scores, strengths, improvements, and sample answers
- üîÑ **Contextual Questioning**: References your specific projects and achievements

---

## Architecture & Design Decisions

### Overall Architecture Philosophy

**Goal**: Create a production-grade AI interview platform that feels as close to a real interview as possible while maintaining simplicity and extensibility.

### 1. Technology Stack Choices

#### **Backend: FastAPI**
**Decision**: Chose FastAPI over Flask, Django, Streamlit, or Gradio

**Reasoning**:
- **Performance**: ASGI-based async support for handling multiple concurrent interviews
- **Modern**: Native Pydantic integration for request/response validation
- **Developer Experience**: Automatic API documentation with Swagger UI
- **File Upload**: Excellent multipart/form-data handling for resume uploads
- **Type Safety**: Full type hints support improves code maintainability
- **Lightweight**: Fast startup, minimal boilerplate compared to Django
- **Production-Ready**: Easy to scale and deploy (works with Uvicorn, Gunicorn, containers)

**Alternatives Considered**:
- Flask: Too basic, lacks async, needs extensions for everything
- Django: Too heavyweight for this use case
- Streamlit: Great for demos but limited control over UI/UX
- Gradio: Similar issues to Streamlit, less customizable

#### **AI Model: Google Gemini 1.5 Pro**
**Decision**: Use Gemini 1.5 Pro exclusively

**Reasoning**:
- **Multimodal**: Native PDF processing without external libraries
- **Context Window**: 1M+ token context handles long conversations and resumes
- **Quality**: Excellent instruction following and conversational abilities
- **Cost-Effective**: Competitive pricing with generous free tier
- **Speed**: Fast response times for real-time interview experience
- **JSON Mode**: Reliable structured output for feedback generation

**Why Not Others**:
- OpenAI GPT-4: More expensive, requires separate PDF parsing
- Claude: Excellent quality but API access more limited
- Open Source LLMs: Quality inconsistent, requires hosting infrastructure

#### **Frontend: Vanilla JavaScript + Modern CSS**
**Decision**: No React, Vue, or frontend framework

**Reasoning**:
- **Simplicity**: Single `python app.py` runs everything - no npm, webpack, build steps
- **Fast Load**: No framework overhead, immediate page loads
- **Browser APIs**: Direct access to Web Speech API without abstractions
- **Easy Customization**: Anyone can modify HTML/CSS without learning a framework
- **SEO-Friendly**: Server-side templates render instantly
- **Deployment**: No separate frontend build/deployment process

**Modern CSS Approach**:
- CSS Grid/Flexbox for layouts (no Bootstrap bloat)
- CSS custom properties (variables) for theming
- Modern animations (cubic-bezier, backdrop-filter)
- Responsive design with media queries
- Glassmorphism and gradient effects for premium feel

### 2. State Management

#### **In-Memory Session Storage**
**Decision**: Python dictionary keyed by UUID session IDs

**Reasoning**:
- **Simplicity**: Perfect for local development and demos
- **Speed**: Instant access, no database overhead
- **Sufficient**: Interviews are short-lived (15-30 minutes)
- **Upgrade Path**: Easy to swap with Redis/PostgreSQL later

**Structure**:
```python
sessions[session_id] = {
    "role": str,
    "experience_level": str,
    "company_type": str,
    "resume_text": str,           # Full extracted text
    "resume_summary": str,         # AI-generated summary
    "conversation_history": [],    # All Q&A pairs
    "current_question": str,
    "question_count": int,
    "feedback": dict or None
}
```

**Production Considerations**:
- Add Redis for multi-instance deployments
- Add PostgreSQL for long-term storage and analytics
- Implement session expiration (TTL)

### 3. Prompt Engineering Strategy

#### **Conversational AI Design**
**Decision**: Create distinct AI personas with human characteristics

**Alex (Interviewer)**:
- Friendly yet professional personality
- Uses natural language patterns ("That's interesting...", "I see...", "Got it...")
- Asks ONE question at a time (human-like pacing)
- References specific things candidates say
- Varies question types organically
- Acknowledges before transitioning topics

**Sarah (Feedback Coach)**:
- Constructive and specific feedback style
- References actual conversation moments
- Provides actionable improvement steps
- Balances encouragement with honest assessment

**Why This Matters**:
- Generic prompts produce robotic, interrogation-style questions
- Human-like conversation reduces candidate stress
- Specific references make feedback memorable
- Realistic practice translates to better real interviews

#### **Prompt Template Structure**

**Three-Stage Approach**:

1. **Initial Question Generation**
```
Role + Level + Company Context
‚Üì
Resume Summary (if available)
‚Üì
Opening Question Strategy
‚Üì
Natural, Welcoming Question
```

2. **Follow-up Generation**
```
Full Conversation History (last 3 exchanges)
‚Üì
Resume Context
‚Üì
Interview Stage (question N of ~10)
‚Üì
Natural Follow-up Logic
```

3. **Feedback Generation**
```
Complete Transcript
‚Üì
Resume Context
‚Üì
Structured JSON Output
‚Üì
Specific, Actionable Feedback
```

**Key Prompt Engineering Techniques**:
- **Role-playing**: "You are Alex, an experienced interviewer..."
- **Constraints**: "Ask ONE question", "Keep it 1-3 sentences"
- **Examples**: Show desired output format
- **Context Injection**: Provide resume summary, conversation history
- **Output Control**: "Return ONLY the question, nothing else"
- **Personality Traits**: "Be curious", "Be engaging", "Show genuine interest"

### 4. Resume Processing Pipeline

#### **Decision**: Use Gemini API for PDF extraction instead of PyPDF2/pdfplumber

**Reasoning**:
- **Multimodal Understanding**: Gemini understands document structure, not just text
- **Format Handling**: Works with complex PDFs (columns, tables, images)
- **No Dependencies**: Reduces library conflicts and installation issues
- **Quality**: Better extraction of poorly formatted PDFs
- **Consistency**: Same AI model for extraction and question generation

**Pipeline**:
```
Upload PDF/TXT
‚Üì
Base64 Encode (for PDF)
‚Üì
Gemini Extraction (structured prompt)
‚Üì
Gemini Analysis (resume summary)
‚Üì
Store in Session
‚Üì
Inject into Interview Prompts
```

**Analysis Strategy**:
- Extract key experiences relevant to role
- Identify skills and technologies
- Find notable achievements
- Spot potential probe points
- Note any gaps or areas needing clarification

**Why Two-Step (Extract ‚Üí Analyze)**:
- Separation of concerns
- Reusable analysis for different roles
- Better quality summaries than raw text
- Focused interview questions

### 5. Frontend Design Decisions

#### **Visual Design Philosophy**

**Goal**: Create a premium, AI-product aesthetic that conveys professionalism and cutting-edge technology.

**Design Language Inspiration**:
- OpenAI ChatGPT: Clean, modern, professional
- Anthropic Claude: Sophisticated gradient usage
- Google Gemini: Sleek dark theme
- Linear: Attention to micro-interactions

**Color System**:
```css
Primary Gradient: Blue ‚Üí Purple ‚Üí Pink
Background: Deep dark (#0a0a0f)
Cards: Glassmorphism with backdrop blur
Accents: Subtle glows and borders
```

**Why Dark Theme**:
- Modern AI platforms use dark themes
- Reduces eye strain during long sessions
- Makes gradient accents pop
- Premium, professional feel
- Better for video calls (if user screen shares)

**Typography**:
- Inter font family (modern, readable)
- Gradient text for headings (premium feel)
- Proper hierarchy (2.5em ‚Üí 1.8em ‚Üí 1.05em)
- Negative letter-spacing for headings (-0.02em)
- Increased line-height for readability (1.7)

**Animation Philosophy**:
- Smooth, natural transitions (cubic-bezier)
- Subtle micro-interactions on hover
- Fade-in-up for new messages (0.4s)
- Staggered animations for feedback sections
- Pulse effect for recording state
- Never over-animate (distraction vs. delight)

#### **Full-Screen Layout**
**Decision**: Remove restrictive containers, use full viewport

**Reasoning**:
- Modern apps use full screen (Notion, Figma, Claude)
- Better use of screen real estate
- More immersive experience
- Professional appearance
- Scales better on large monitors

**Layout Strategy**:
```
Header: Sticky, 40px padding, blurred background
Main: Flex-grow, max-width 1600px, centered
Interview: Grid layout, chat fills vertical space
```

#### **Voice Interface Design**

**Decision**: Use browser Web Speech API, not cloud services

**Reasoning**:
- **Privacy**: No audio sent to external servers
- **Cost**: Free, no API limits
- **Latency**: Instant, no network delay
- **Simplicity**: Works in modern browsers out-of-box
- **Fallback**: Graceful degradation to text-only

**UX Patterns**:
- Clear visual feedback (recording state, pulse animation)
- Status messages ("Listening...", "Got it!")
- Disable recording during processing (prevent overlaps)
- Auto-read interviewer questions via TTS

### 6. API Design

#### **RESTful Endpoints**

**Decision**: Simple REST over WebSockets or GraphQL

**Reasoning**:
- **Simplicity**: Easy to understand and debug
- **Sufficient**: Interviews are request-response, not real-time streaming
- **Caching**: Standard HTTP caching works
- **Tools**: All HTTP tools work (Postman, curl, browser DevTools)

**Endpoint Design**:
```
POST /api/start-interview     ‚Üí Create session, first question
POST /api/submit-answer        ‚Üí Store answer, next question  
POST /api/end-interview        ‚Üí Generate feedback
GET  /api/session/{id}         ‚Üí Retrieve session data
GET  /interview/{id}           ‚Üí Render interview page
GET  /feedback/{id}            ‚Üí Render feedback page
```

**Why This Structure**:
- Clear separation of concerns
- Easy to add authentication later
- Supports future mobile app
- Can add WebSocket layer if needed (real-time features)

### 7. Error Handling & Resilience

#### **Graceful Degradation Strategy**

**Voice Features**:
- Check for Web Speech API availability
- Show clear message if not supported
- Never block core functionality

**Resume Parsing**:
- Try Gemini extraction
- Fall back to basic text if PDF fails
- Continue interview without resume if upload fails
- Never fail the entire session

**AI Generation**:
- Wrap all API calls in try-catch
- Provide fallback responses
- Log errors for debugging
- Show user-friendly messages

**JSON Parsing**:
- Strip markdown code fences
- Handle malformed JSON
- Return default structured feedback

### 8. Security & Privacy Considerations

#### **Current Design (Development)**:
- No authentication (single-user local app)
- Sessions in memory (cleared on restart)
- No data persistence
- API key in environment variable

#### **Production Recommendations**:
- Add user authentication (OAuth, JWT)
- Encrypt session data
- Add rate limiting
- Store resumes securely (encrypted storage)
- Add CSRF protection
- Implement CORS properly
- Use HTTPS only
- Add input validation/sanitization
- Log security events

### 9. Scalability Considerations

#### **Current Bottlenecks**:
- In-memory state (single instance only)
- Gemini API rate limits
- No caching

#### **Scaling Path**:

**Phase 1: Multi-Instance (100-1000 users)**:
- Add Redis for session storage
- Use Redis pub/sub for inter-instance communication
- Load balancer with sticky sessions
- Add API response caching

**Phase 2: High Scale (1000-10000 users)**:
- PostgreSQL for permanent storage
- Separate service for resume processing
- Queue system (Celery/RQ) for long-running tasks
- CDN for static assets
- Response streaming for better UX

**Phase 3: Enterprise (10000+ users)**:
- Microservices architecture
- Kubernetes orchestration
- AI model fine-tuning
- Multi-region deployment
- Analytics and monitoring

### 10. Testing Strategy (Future)

**Unit Tests**:
- Prompt template rendering
- Session state management
- Resume extraction logic
- Feedback parsing

**Integration Tests**:
- API endpoint behavior
- File upload handling
- Gemini API mocking

**E2E Tests**:
- Full interview flow
- Resume upload ‚Üí interview ‚Üí feedback
- Voice interaction (if feasible)

**Load Tests**:
- Concurrent interview sessions
- API rate limit handling

---

## Prerequisites

- Python 3.8 or higher
- A Google Gemini API key (get one at [Google AI Studio](https://makersuite.google.com/app/apikey))

---

## Installation

1. **Clone or download this project**

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Set your Gemini API key**

   **On Linux/Mac:**
   ```bash
   export GEMINI_API_KEY="your-api-key-here"
   ```

   **On Windows (Command Prompt):**
   ```cmd
   set GEMINI_API_KEY=your-api-key-here
   ```

   **On Windows (PowerShell):**
   ```powershell
   $env:GEMINI_API_KEY="your-api-key-here"
   ```

   **Alternative: Create .env file** (requires `python-dotenv`):
   ```
   GEMINI_API_KEY=your-api-key-here
   ```

---

## Usage

1. **Start the application**
```bash
python app.py
```

2. **Open your browser**
   
   Navigate to: `http://localhost:8000`

3. **Start practicing!**
   - Select your target role
   - Choose your experience level
   - Optionally specify company type
   - **Upload your resume (PDF, TXT, DOC, DOCX)** for personalized questions
   - Click "Start Interview"

4. **During the interview**
   - **Text mode**: Type your answers and click "Send" (or press Enter)
   - **Voice mode**: Click "üé§ Voice Answer" to speak your response
     - The browser will convert your speech to text
     - The interviewer's questions will be read aloud (if TTS is supported)
   - Answer questions naturally
   - The AI will ask relevant follow-ups based on what you say

5. **Get feedback**
   - Click "End Interview & Get Feedback" when ready
   - Review your scores across multiple dimensions
   - See specific strengths and areas to improve
   - Read sample improved answers for questions you struggled with

---

## Project Structure

```
interview-practice-partner/
‚îÇ
‚îú‚îÄ‚îÄ app.py                      # Main FastAPI application (500+ lines)
‚îÇ   ‚îú‚îÄ‚îÄ API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ Session management
‚îÇ   ‚îú‚îÄ‚îÄ Resume processing
‚îÇ   ‚îú‚îÄ‚îÄ Gemini integration
‚îÇ   ‚îî‚îÄ‚îÄ Prompt templates
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ README.md                   # This file
‚îÇ
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îú‚îÄ‚îÄ style.css              # Modern CSS (700+ lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dark theme
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Glassmorphism
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Animations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Responsive design
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ script.js              # Voice functionality (150+ lines)
‚îÇ       ‚îú‚îÄ‚îÄ Web Speech API
‚îÇ       ‚îú‚îÄ‚îÄ Speech recognition
‚îÇ       ‚îî‚îÄ‚îÄ Text-to-speech
‚îÇ
‚îî‚îÄ‚îÄ templates/
    ‚îú‚îÄ‚îÄ index.html             # Home/setup page
    ‚îÇ   ‚îú‚îÄ‚îÄ Role selection
    ‚îÇ   ‚îú‚îÄ‚îÄ Experience level
    ‚îÇ   ‚îî‚îÄ‚îÄ Resume upload
    ‚îÇ
    ‚îú‚îÄ‚îÄ interview.html         # Interview interface
    ‚îÇ   ‚îú‚îÄ‚îÄ Chat container
    ‚îÇ   ‚îú‚îÄ‚îÄ Voice controls
    ‚îÇ   ‚îî‚îÄ‚îÄ Input section
    ‚îÇ
    ‚îî‚îÄ‚îÄ feedback.html          # Feedback display
        ‚îú‚îÄ‚îÄ Overall score
        ‚îú‚îÄ‚îÄ Dimension scores
        ‚îú‚îÄ‚îÄ Strengths/improvements
        ‚îî‚îÄ‚îÄ Sample answers
```

---

## How It Works

### 1. Session Initialization
```
User fills form ‚Üí Uploads resume (optional) ‚Üí Submit
‚Üì
Backend creates UUID session
‚Üì
Gemini extracts resume text (if PDF)
‚Üì
Gemini analyzes resume ‚Üí Creates summary
‚Üì
Generate first question (resume-aware)
‚Üì
Store session state
‚Üì
Redirect to interview page
```

### 2. Interview Flow
```
Display question ‚Üí User answers (text/voice)
‚Üì
Submit answer to backend
‚Üì
Store Q&A in history
‚Üì
Gemini generates follow-up:
  - Analyzes last 3 exchanges
  - References resume summary
  - Considers question number (1-10)
  - Applies conversational patterns
‚Üì
Return next question
‚Üì
Repeat until user ends interview
```

### 3. Feedback Generation
```
User clicks "End Interview"
‚Üì
Backend compiles full transcript
‚Üì
Gemini evaluates:
  - Overall performance
  - Communication clarity
  - Technical depth
  - Role-specific skills
  - Resume utilization
‚Üì
Generate JSON feedback:
  - Scores (1-10)
  - Specific strengths
  - Actionable improvements
  - Sample improved answers
‚Üì
Render feedback page
```

### 4. Resume Processing Deep Dive

**PDF Upload**:
```python
File upload ‚Üí Read bytes ‚Üí Base64 encode
‚Üì
Gemini API call with document input
‚Üì
Structured extraction prompt
‚Üì
Return formatted text with sections
```

**Analysis**:
```python
Extracted text + Role
‚Üì
Gemini generates 150-200 word summary:
  - Relevant experiences
  - Key skills/technologies
  - Notable achievements
  - Areas to probe
  - Gaps to explore
‚Üì
Summary stored in session
‚Üì
Injected into all interview prompts
```

**Question Generation with Resume**:
```python
"You worked on [Project X] at [Company Y]"
"I see you have experience with [Technology Z]"
"Tell me about [Achievement A] from your resume"
"Walk me through your role at [Company B]"
```

---

## Voice Mode Requirements

Voice features use the **Web Speech API**:

**Speech Recognition**:
- Supported: Chrome, Edge, Safari (with microphone permission)
- Language: English (en-US)
- Mode: Single utterance (click to start/stop)

**Text-to-Speech**:
- Supported: Most modern browsers
- Automatic: Reads interviewer questions aloud
- Configurable: Rate, pitch, voice selection

**Fallback**:
- If not available, gracefully disables voice button
- Shows clear message to user
- All functionality works in text mode

---

## Customization

### Adding More Roles

Edit `FOCUS_AREAS` in `app.py`:

```python
FOCUS_AREAS = {
    "Product Manager": """
- Product strategy and vision
- User research and empathy
- Roadmap prioritization
- Stakeholder management
- Metrics and KPIs
- Launch and go-to-market""",
    # Add more roles...
}
```

Update `templates/index.html`:
```html
<option value="Product Manager">Product Manager</option>
```

### Adjusting Interview Length

Modify the prompt in `generate_followup_question()`:

```python
# Current: "approximately 8-10 questions"
# Change to: "approximately 5-7 questions" for shorter interviews
```

### Changing AI Model

Update `get_gemini_model()` in `app.py`:

```python
return genai.GenerativeModel('gemini-2.5-flash')  # Faster, cheaper

```

### Customizing Feedback Criteria

Edit `FEEDBACK_SYSTEM_PROMPT` in `app.py`:

```python
"dimension_scores": {
    "communication_clarity": ...,
    "confidence_structure": ...,
    "technical_knowledge": ...,
    "role_specific_skills": ...,
    "your_custom_dimension": ...  # Add new dimension
}
```

### Modifying Visual Theme

Edit CSS variables in `static/style.css`:

```css
:root {
    --primary-gradient: linear-gradient(135deg, #your-colors);
    --dark-bg: #your-background;
    --accent-blue: #your-accent;
    /* Customize all colors */
}
```

---

## Troubleshooting

### "GEMINI_API_KEY environment variable not set"
- Ensure you've exported the variable in the same terminal where you run `python app.py`
- Check that your API key is valid and active
- Try hardcoding temporarily for testing (not recommended for production)

### Voice not working
- Check browser console for errors
- Ensure microphone permissions are granted
- Voice mode requires HTTPS in production (works on localhost)
- Try Chrome or Edge for best compatibility
- Check if Web Speech API is available: open browser console and type `'webkitSpeechRecognition' in window`

### Questions seem generic
- **Upload your resume** for personalized questions about your actual experience
- The AI learns from your answers - provide detailed, specific responses
- Make sure you've selected the correct role and experience level
- Reference specific projects and technologies you've worked with

### Resume not being parsed correctly
- Supported formats: PDF, TXT, DOC, DOCX (Max 5MB)
- Ensure your resume has clear sections (Experience, Skills, Education)
- PDFs work best when they contain actual text (not scanned images)
- Try converting to plain text if issues persist

### Interview feels too short/long
- Default: 8-10 questions
- Customize in prompt templates (search "approximately 8-10 questions")
- You can always end early with "End Interview" button

### Feedback generation fails
- Check if conversation has at least one Q&A pair
- Verify Gemini API rate limits haven't been exceeded
- Check terminal logs for JSON parsing errors
- Try interview with more substantial answers

### Application crashes on startup
- Verify all dependencies installed: `pip install -r requirements.txt`
- Check Python version: `python --version` (need 3.8+)
- Ensure port 8000 is not in use by another application
- Check for syntax errors if you modified code

---

## Development Notes

### Current Limitations

**State Management**:
- Sessions stored in memory (lost on restart)
- Single instance only (no load balancing)
- No session persistence or recovery

**Scalability**:
- No caching (every request hits Gemini API)
- No rate limiting (could exceed API quotas)
- No queue system for long-running tasks

**Security**:
- No authentication or authorization
- No input sanitization (okay for local use)
- No CSRF/XSS protection
- API key in environment variable (okay for development)

### Production Deployment Checklist

**Infrastructure**:
- [ ] Deploy to cloud (AWS, GCP, Azure, Railway, Render)
- [ ] Use PostgreSQL for session storage
- [ ] Add Redis for caching and rate limiting
- [ ] Set up proper logging and monitoring
- [ ] Configure environment variables securely
- [ ] Use HTTPS only

**Security**:
- [ ] Add user authentication (OAuth, JWT)
- [ ] Implement rate limiting per user
- [ ] Sanitize all user inputs
- [ ] Add CSRF tokens
- [ ] Encrypt sensitive data
- [ ] Add security headers

**Performance**:
- [ ] Cache common prompts/responses
- [ ] Implement response streaming
- [ ] Optimize database queries
- [ ] Add CDN for static assets
- [ ] Compress responses (gzip)

**Features**:
- [ ] User accounts and profiles
- [ ] Interview history and analytics
- [ ] Practice multiple interviews
- [ ] Share feedback with others
- [ ] Export feedback as PDF
- [ ] Schedule mock interviews

### Future Enhancements

**AI Improvements**:
- Fine-tune models on real interview transcripts
- Add multi-turn clarification loops
- Implement difficulty adaptation (easier if struggling)
- Add industry-specific interview styles

**Features**:
- Video interview mode (camera on)
- Real-time hints and coaching
- Interview recording and playback
- Peer comparison (anonymized)
- Interview prep courses
- Company-specific interview prep

**Analytics**:
- Track improvement over time
- Identify weak areas automatically
- Benchmark against others
- Success rate tracking (if users report outcomes)

---

## Performance Considerations

### Latency Sources
1. **Gemini API**: 1-3 seconds per generation
2. **Resume Processing**: 3-5 seconds for PDF extraction
3. **Network**: Varies by location and ISP

### Optimization Strategies
- Cache frequently generated prompts
- Stream responses (future enhancement)
- Use Gemini Flash for faster questions
- Pre-generate common questions
- Implement request batching

---

## Contributing

This is a demonstration project, but suggestions welcome:

1. **Bug Reports**: Note the steps to reproduce
2. **Feature Requests**: Describe the use case
3. **Code Improvements**: Focus on clarity and maintainability
4. **Documentation**: Help improve explanations

---

## License

This is a demonstration project. Modify and use as needed.

---

## Acknowledgments

- **Google Gemini**: Powering the AI interview capabilities
- **FastAPI**: Modern Python web framework
- **Web Speech API**: Browser-based voice capabilities
- **Interview Best Practices**: Inspired by tech industry standards

---

## Support

For issues or questions:

1. Check that all dependencies are installed: `pip list`
2. Verify your API key is set correctly: `echo $GEMINI_API_KEY`
3. Check the terminal output for error messages
4. Ensure you're using Python 3.8+: `python --version`
5. Try with a simple example (no resume) first
6. Check browser console for frontend errors (F12)

---

## Changelog

**v1.0.0** - Initial Release
- Core interview functionality
- Role-based questioning
- Voice mode support
- Detailed feedback generation

**v1.1.0** - Resume Enhancement
- Resume upload and parsing
- Personalized questions
- Resume-aware feedback
- Enhanced prompt engineering
- Human-like conversation patterns

**v1.2.0** - Design Overhaul
- Modern dark theme
- Glassmorphism effects
- Full-screen layout
- Premium AI product aesthetic
- Improved animations and micro-interactions

---

**Built with ‚ù§Ô∏è using FastAPI, Google Gemini API, and modern web technologies**
